{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nFinding a minimum in a flat neighborhood\n=========================================\n\nAn excercise of finding minimum. This excercise is hard because the\nfunction is very flat around the minimum (all its derivatives are zero).\nThus gradient information is unreliable.\n\nThe function admits a minimum in [0, 0]. The challenge is to get within\n1e-7 of this minimum, starting at x0 = [1, 1].\n\nThe solution that we adopt here is to give up on using gradient or\ninformation based on local differences, and to rely on the Powell\nalgorithm. With 162 function evaluations, we get to 1e-8 of the\nsolution.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np\nfrom scipy import optimize\nimport pylab as pl\n\ndef f(x):\n    return np.exp(-1/(.01*x[0]**2 + x[1]**2))\n\n# A well-conditionned version of f:\ndef g(x):\n    return f([10*x[0], x[1]])\n\n# The gradient of g. We won't use it here for the optimization.\ndef g_prime(x):\n    r = np.sqrt(x[0]**2 + x[1]**2)\n    return 2/r**3*g(x)*x/r\n\nx_min = optimize.fmin_powell(g, [1, 1], xtol=1e-10)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Some pretty plotting\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "pl.figure(0)\npl.clf()\nt = np.linspace(-1.1, 1.1, 100)\npl.plot(t, f([0, t]))\n\npl.figure(1)\npl.clf()\nX, Y = np.mgrid[-1.5:1.5:100j, -1.1:1.1:100j]\npl.imshow(f([X, Y]).T, cmap=pl.cm.gray_r, extent=[-1.5, 1.5, -1.1, 1.1],\n          origin='lower')\npl.contour(X, Y, f([X, Y]), cmap=pl.cm.gnuplot)\n\n# Plot the gradient\ndX, dY = g_prime([.1*X[::5, ::5], Y[::5, ::5]])\n# Adjust for our preconditioning\ndX *= .1\npl.quiver(X[::5, ::5], Y[::5, ::5], dX, dY, color='.5')\n\n# Plot our solution\npl.plot(x_min[0], x_min[1], 'r+', markersize=15)\n\npl.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}